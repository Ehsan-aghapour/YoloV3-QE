{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KimMZUVqcJ8_"
   },
   "source": [
    "##### Copyright 2021 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-10-20T13:29:24.749610Z",
     "iopub.status.busy": "2022-10-20T13:29:24.749135Z",
     "iopub.status.idle": "2022-10-20T13:29:24.753136Z",
     "shell.execute_reply": "2022-10-20T13:29:24.752461Z"
    },
    "id": "BRQ6HQ8zcV5v"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlWzg1D9_EhW"
   },
   "source": [
    "# Inspecting Quantization Errors with Quantization Debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLoHL19yb-a0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/performance/quantization_debugger\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorflow/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWO_yYDGcGWY"
   },
   "source": [
    "Although full-integer quantization provides improved model size and latency, the\n",
    "quantized model won't always work as expected. It's usually expected for the\n",
    "model quality (e.g. accuracy, mAP, WER) to be slightly lower than the original\n",
    "float model. However, there are cases where the model quality can go below your\n",
    "expectation or generated completely wrong results.\n",
    "\n",
    "When this problem happens, it's tricky and painful to spot the root cause of the\n",
    "quantization error, and it's even more difficult to fix the quantization error.\n",
    "To assist this model inspection process, **quantization debugger** can be used\n",
    "to identify problematic layers, and **selective quantization** can leave those\n",
    "problematic layers in float so that the model accuracy can be recovered at the\n",
    "cost of reduced benefit from quantization.\n",
    "\n",
    "Note: This API is experimental, and there might be breaking changes in the API\n",
    "in the course of improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kD29R1I_Mn6"
   },
   "source": [
    "## Quantization Debugger\n",
    "\n",
    "Quantization debugger makes it possible to do quantization quality metric\n",
    "analysis in the existing model. Quantization debugger can automate processes for\n",
    "running model with a debug dataset, and collecting quantization quality metrics\n",
    "for each tensors.\n",
    "\n",
    "Note: Quantization debugger and selective quantization currently only works for\n",
    "full-integer quantization with int8 activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "221Qon7G_PmZ"
   },
   "source": [
    "### Prerequisites\n",
    "\n",
    "If you already have a pipeline to quantize a model, you have all necessary\n",
    "pieces to run quantization debugger!\n",
    "\n",
    "*   Model to quantize\n",
    "*   Representative dataset\n",
    "\n",
    "In addition to model and data, you will need to use a data processing framework\n",
    "(e.g. pandas, Google Sheets) to analyze the exported results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTEEzJWo_iZ_"
   },
   "source": [
    "### Setup\n",
    "\n",
    "This section prepares libraries, MobileNet v3 model, and test dataset of 100\n",
    "images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:29:24.761151Z",
     "iopub.status.busy": "2022-10-20T13:29:24.760694Z",
     "iopub.status.idle": "2022-10-20T13:29:56.104175Z",
     "shell.execute_reply": "2022-10-20T13:29:56.103267Z"
    },
    "id": "l7epUDUP_6qo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.11.0rc1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tensorflow-2.11.0rc1:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully uninstalled tensorflow-2.11.0rc1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tf_nightly-2.12.0.dev20221020-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (592.0 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-estimator-nightly~=2.12.0.dev\r\n",
      "  Downloading tf_estimator_nightly-2.12.0.dev2022102008-py2.py3-none-any.whl (439 kB)\r\n",
      "Requirement already satisfied: packaging in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (21.3)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (1.14.1)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (14.0.6)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (2.0.1)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (1.6.3)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (0.4.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (3.3.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (0.27.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (3.7.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tb-nightly~=2.11.0.a\r\n",
      "  Downloading tb_nightly-2.11.0a20221020-py3-none-any.whl (6.0 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (65.5.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (1.50.0)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (1.23.4)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (1.16.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (1.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (4.4.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (0.2.0)\r\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (3.19.6)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tf-nightly) (22.9.24)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-nightly~=2.12.0.dev\r\n",
      "  Downloading keras_nightly-2.12.0.dev2022102007-py2.py3-none-any.whl (1.7 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from astunparse>=1.6.0->tf-nightly) (0.37.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tb-nightly~=2.11.0.a->tf-nightly) (0.6.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: werkzeug>=1.0.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tb-nightly~=2.11.0.a->tf-nightly) (2.2.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tb-nightly~=2.11.0.a->tf-nightly) (3.4.1)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tb-nightly~=2.11.0.a->tf-nightly) (2.13.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tb-nightly~=2.11.0.a->tf-nightly) (0.4.6)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tb-nightly~=2.11.0.a->tf-nightly) (2.28.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tb-nightly~=2.11.0.a->tf-nightly) (1.8.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from packaging->tf-nightly) (3.0.9)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly) (0.3.0rc1)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly) (4.9)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly) (5.2.0)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.11.0.a->tf-nightly) (1.3.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from markdown>=2.6.8->tb-nightly~=2.11.0.a->tf-nightly) (5.0.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=2017.4.17 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly) (2022.9.24)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly) (1.26.12)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.11.0.a->tf-nightly) (3.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from werkzeug>=1.0.1->tb-nightly~=2.11.0.a->tf-nightly) (2.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly~=2.11.0.a->tf-nightly) (3.9.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.11.0.a->tf-nightly) (0.5.0rc2)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.11.0.a->tf-nightly) (3.2.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tf-estimator-nightly, keras-nightly, tb-nightly, tf-nightly\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed keras-nightly-2.12.0.dev2022102007 tb-nightly-2.11.0a20221020 tf-estimator-nightly-2.12.0.dev2022102008 tf-nightly-2.12.0.dev20221020\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (4.7.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: etils[epath] in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (0.8.0)\r\n",
      "Requirement already satisfied: termcolor in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (2.0.1)\r\n",
      "Requirement already satisfied: tqdm in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (4.64.1)\r\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (3.19.6)\r\n",
      "Requirement already satisfied: toml in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (0.10.2)\r\n",
      "Requirement already satisfied: six in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (1.16.0)\r\n",
      "Requirement already satisfied: promise in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (2.3)\r\n",
      "Requirement already satisfied: dill in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (0.3.5.1)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (2.28.1)\r\n",
      "Requirement already satisfied: tensorflow-metadata in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (1.10.0)\r\n",
      "Requirement already satisfied: numpy in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (1.23.4)\r\n",
      "Requirement already satisfied: absl-py in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_datasets) (1.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2022.9.24)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.12)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from etils[epath]->tensorflow_datasets) (3.9.0)\r\n",
      "Requirement already satisfied: importlib_resources in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from etils[epath]->tensorflow_datasets) (5.10.0)\r\n",
      "Requirement already satisfied: typing_extensions in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from etils[epath]->tensorflow_datasets) (4.4.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.4)\r\n"
     ]
    }
   ],
   "source": [
    "# Quantization debugger is available from TensorFlow 2.7.0\n",
    "!pip uninstall -y tensorflow\n",
    "!pip install tf-nightly\n",
    "!pip install tensorflow_datasets --upgrade  # imagenet_v2 needs latest checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:29:56.108833Z",
     "iopub.status.busy": "2022-10-20T13:29:56.108564Z",
     "iopub.status.idle": "2022-10-20T13:29:58.828751Z",
     "shell.execute_reply": "2022-10-20T13:29:58.828049Z"
    },
    "id": "LLsgiUZe_hIa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 13:38:03.823056: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-14 13:38:03.826921: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-02-14 13:38:03.880944: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-02-14 13:38:03.881458: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 13:38:04.566908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-10-20T13:29:58.833063Z",
     "iopub.status.busy": "2022-10-20T13:29:58.832577Z",
     "iopub.status.idle": "2022-10-20T13:30:20.763915Z",
     "shell.execute_reply": "2022-10-20T13:30:20.763042Z"
    },
    "id": "veWjO3u32vzz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppioyzryd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmppioyzryd/assets\n",
      "/home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-02-14 13:40:33.875285: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-02-14 13:40:33.875309: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-02-14 13:40:33.875462: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmppioyzryd\n",
      "2023-02-14 13:40:33.880914: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-02-14 13:40:33.880944: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmppioyzryd\n",
      "2023-02-14 13:40:33.905861: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-02-14 13:40:34.116173: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmppioyzryd\n",
      "2023-02-14 13:40:34.182478: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 307015 microseconds.\n",
      "2023-02-14 13:40:34.541378: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2116] Estimated count of arithmetic ops: 115.112 M  ops, equivalently 57.556 M  MACs\n",
      "2023-02-14 13:40:34.572713: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-02-14 13:40:34.573069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "2023-02-14 13:40:37.509439: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2116] Estimated count of arithmetic ops: 115.112 M  ops, equivalently 57.556 M  MACs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2926624"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Boilerplates and helpers\n",
    "MODEL_URI = 'https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5'\n",
    "\n",
    "\n",
    "def process_image(data):\n",
    "  data['image'] = tf.image.resize(data['image'], (224, 224)) / 255.0\n",
    "  return data\n",
    "\n",
    "\n",
    "# Representative dataset\n",
    "def representative_dataset(dataset):\n",
    "\n",
    "  def _data_gen():\n",
    "    for data in dataset.batch(1):\n",
    "      yield [data['image']]\n",
    "\n",
    "  return _data_gen\n",
    "\n",
    "\n",
    "def eval_tflite(tflite_model, dataset):\n",
    "  \"\"\"Evaluates tensorflow lite classification model with the given dataset.\"\"\"\n",
    "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_idx = interpreter.get_input_details()[0]['index']\n",
    "  output_idx = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "  results = []\n",
    "\n",
    "  for data in representative_dataset(dataset)():\n",
    "    interpreter.set_tensor(input_idx, data[0])\n",
    "    interpreter.invoke()\n",
    "    results.append(interpreter.get_tensor(output_idx).flatten())\n",
    "\n",
    "  results = np.array(results)\n",
    "  gt_labels = np.array(list(dataset.map(lambda data: data['label'] + 1)))\n",
    "  accuracy = (\n",
    "      np.sum(np.argsort(results, axis=1)[:, -5:] == gt_labels.reshape(-1, 1)) /\n",
    "      gt_labels.size)\n",
    "  print(f'Top-5 accuracy (quantized): {accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(shape=(224, 224, 3), batch_size=1),\n",
    "  hub.KerasLayer(MODEL_URI)\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics='sparse_top_k_categorical_accuracy')\n",
    "model.build([1, 224, 224, 3])\n",
    "model.save('k.h5')\n",
    "# Prepare dataset with 100 examples\n",
    "ds = tfds.load('imagenet_v2', split='test[:1%]')\n",
    "ds = ds.map(process_image)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.representative_dataset = representative_dataset(ds)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_model = converter.convert()\n",
    "open('q.tflite', \"wb\").write(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:20.767730Z",
     "iopub.status.busy": "2022-10-20T13:30:20.767429Z",
     "iopub.status.idle": "2022-10-20T13:30:24.545446Z",
     "shell.execute_reply": "2022-10-20T13:30:24.544613Z"
    },
    "id": "7mX-R-xK4ADB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 13:43:24.987205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-02-14 13:43:24.987579: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 34ms/step - loss: 5.7098 - sparse_top_k_categorical_accuracy: 0.8200\n",
      "Top-5 accuracy (float): 82.00%\n"
     ]
    }
   ],
   "source": [
    "test_ds = ds.map(lambda data: (data['image'], data['label'] + 1)).batch(16)\n",
    "loss, acc = model.evaluate(test_ds)\n",
    "print(f'Top-5 accuracy (float): {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:24.549148Z",
     "iopub.status.busy": "2022-10-20T13:30:24.548650Z",
     "iopub.status.idle": "2022-10-20T13:30:28.229831Z",
     "shell.execute_reply": "2022-10-20T13:30:28.228969Z"
    },
    "id": "Mnp6yBnJSCoh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2023-02-14 13:43:37.053206: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-02-14 13:43:37.053672: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 accuracy (quantized): 51.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 13:43:37.980713: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2023-02-14 13:43:37.980955: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    }
   ],
   "source": [
    "eval_tflite(quantized_model, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tblkk3cxxpuw"
   },
   "source": [
    "We can see that the original model has a much higher top-5 accuracy for our\n",
    "small dataset, while the quantized model has a significant accuracy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBBcfCQw_Wqd"
   },
   "source": [
    "### Step 1. Debugger preparation\n",
    "\n",
    "Easiest way to use the quantization debugger is to provide\n",
    "`tf.lite.TFLiteConverter` that you have been using to quantize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:28.234250Z",
     "iopub.status.busy": "2022-10-20T13:30:28.233647Z",
     "iopub.status.idle": "2022-10-20T13:30:42.071558Z",
     "shell.execute_reply": "2022-10-20T13:30:42.070789Z"
    },
    "id": "NOByihbD_NZZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpscrhcoj5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpscrhcoj5/assets\n",
      "/home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-02-14 13:44:48.369360: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-02-14 13:44:48.369384: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-02-14 13:44:48.369548: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpscrhcoj5\n",
      "2023-02-14 13:44:48.382935: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-02-14 13:44:48.382961: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpscrhcoj5\n",
      "2023-02-14 13:44:48.417324: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-02-14 13:44:48.647883: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpscrhcoj5\n",
      "2023-02-14 13:44:48.721687: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 352138 microseconds.\n",
      "2023-02-14 13:44:49.098490: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2116] Estimated count of arithmetic ops: 115.112 M  ops, equivalently 57.556 M  MACs\n",
      "2023-02-14 13:44:49.154549: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-02-14 13:44:49.154997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "2023-02-14 13:44:52.193496: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2116] Estimated count of arithmetic ops: 230.224 M  ops, equivalently 115.112 M  MACs\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset(ds)\n",
    "\n",
    "# my_debug_dataset should have the same format as my_representative_dataset\n",
    "debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "    converter=converter, debug_dataset=representative_dataset(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vR1IIrmQS9W"
   },
   "source": [
    "### Step 2. Running the debugger and getting the results\n",
    "\n",
    "When you call `QuantizationDebugger.run()`, the debugger will log differences\n",
    "between float tensors and quantized tensors for the same op location, and\n",
    "process them with given metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:42.075288Z",
     "iopub.status.busy": "2022-10-20T13:30:42.075028Z",
     "iopub.status.idle": "2022-10-20T13:30:47.749050Z",
     "shell.execute_reply": "2022-10-20T13:30:47.748290Z"
    },
    "id": "HsUM54g-_E52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 13:45:02.094226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-02-14 13:45:02.094692: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "debugger.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQpX_SBUQXvr"
   },
   "source": [
    "The processed metrics can be accessed with\n",
    "`QuantizationDebugger.layer_statistics`, or can be dumped to a text file in CSV\n",
    "format with `QuantizationDebugger.layer_statistics_dump()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:47.753826Z",
     "iopub.status.busy": "2022-10-20T13:30:47.753567Z",
     "iopub.status.idle": "2022-10-20T13:30:47.761810Z",
     "shell.execute_reply": "2022-10-20T13:30:47.761215Z"
    },
    "id": "U-AGYUAbQUmx"
   },
   "outputs": [],
   "source": [
    "RESULTS_FILE = './debugger_results.csv'\n",
    "with open(RESULTS_FILE, 'w') as f:\n",
    "  debugger.layer_statistics_dump(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:47.765065Z",
     "iopub.status.busy": "2022-10-20T13:30:47.764846Z",
     "iopub.status.idle": "2022-10-20T13:30:48.010747Z",
     "shell.execute_reply": "2022-10-20T13:30:48.009765Z"
    },
    "id": "LQzEi6VnQaen"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op_name,tensor_idx,num_elements,stddev,mean_error,max_abs_error,mean_squared_error,scale,zero_point,tensor_name\n",
      "MUL,227,150528.0,0.0021623536,-2.0737803e-06,0.0039216112,4.713237e-06,0.007843138,-128,predict/hub_input/Mul;predict/hub_input/Mul\n",
      "SUB,231,150528.0,3.170321e-08,0.003921518,0.0039216173,1.5378308e-05,0.007843138,-1,predict/hub_input/Sub;predict/hub_input/Sub\n",
      "CONV_2D,235,200704.0,0.041487794,0.00021645021,0.10227395,0.001726395,0.14247456,-30,predict/MobilenetV3/Conv/BatchNorm/FusedBatchNormV3;predict/MobilenetV3/Conv/BatchNorm/FusedBatchNormV3;predict/MobilenetV3/expanded_conv/project/Conv2D;predict/MobilenetV3/expanded_conv/project/Conv2D;predict/MobilenetV3/Conv/Conv2D;predict/MobilenetV3/Conv/Conv2D\n",
      "HARD_SWISH,239,200704.0,0.029812379,-0.00047046941,0.045248985,0.000893142,0.08929687,-124,predict/MobilenetV3/Conv/hard_swish/mul_1;predict/MobilenetV3/Conv/hard_swish/mul_1;predict/MobilenetV3/Conv/hard_swish/add/y;predict/MobilenetV3/Conv/hard_swish/add/y;predict/MobilenetV3/Conv/hard_swish/Relu6;predict/MobilenetV3/Conv/hard_swish/Relu6;predict/MobilenetV3/Conv/hard_swish/add;predict/MobilenetV3/Conv/hard_swish/add;predict/MobilenetV3/Conv/hard_swish/mul;predict/MobilenetV3/Conv/hard_swish/mul;predict/MobilenetV3/Conv/hard_swish/mul_1/y;predict/MobilenetV3/Conv/hard_swish/mul_1/y\n",
      "DEPTHWISE_CONV_2D,243,50176.0,0.21766528,-0.022612955,0.72389275,0.04796089,0.5087459,-128,predict/MobilenetV3/expanded_conv/depthwise/Relu;predict/MobilenetV3/expanded_conv/depthwise/Relu;predict/MobilenetV3/expanded_conv/depthwise/BatchNorm/FusedBatchNormV3;predict/MobilenetV3/expanded_conv/depthwise/BatchNorm/FusedBatchNormV3;predict/MobilenetV3/expanded_conv/depthwise/depthwise;predict/MobilenetV3/expanded_conv/depthwise/depthwise;predict/MobilenetV3/expanded_conv/project/Conv2D;predict/MobilenetV3/expanded_conv/project/Conv2D\n",
      "MEAN,247,16.0,0.028642809,0.00038988946,0.0488894,0.0008962434,0.10327542,-128,predict/MobilenetV3/expanded_conv/squeeze_excite/Mean;predict/MobilenetV3/expanded_conv/squeeze_excite/Mean\n",
      "CONV_2D,251,8.0,0.010389271,-0.0002389279,0.021622978,0.00012997774,0.048884314,-128,predict/MobilenetV3/expanded_conv/squeeze_excite/Conv/Relu;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv/Relu;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv/BiasAdd;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv/BiasAdd;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv/Conv2D;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv/Conv2D;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv/BiasAdd/ReadVariableOp;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv/BiasAdd/ReadVariableOp\n",
      "CONV_2D,255,16.0,0.0,0.0,0.0,0.0,0.023529412,-128,predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/Relu6;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/Relu6;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/add;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/add;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/BiasAdd/ReadVariableOp;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/BiasAdd/ReadVariableOp;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/BiasAdd;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/BiasAdd;predict/MobilenetV3/expanded_conv/project/Conv2D;predict/MobilenetV3/expanded_conv/project/Conv2D;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/Conv2D;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/Conv2D;predict/MobilenetV3/Conv/hard_swish/add/y;predict/MobilenetV3/Conv/hard_swish/add/y1\n",
      "MUL,259,16.0,0.0,0.0,0.0,0.0,0.003921647,-128,predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/mul;predict/MobilenetV3/expanded_conv/squeeze_excite/Conv_1/mul\n"
     ]
    }
   ],
   "source": [
    "!head ./debugger_results.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4np7VqU-Qfke"
   },
   "source": [
    "For each row in the dump, the op name and index comes first, followed by\n",
    "quantization parameters and error metrics (including\n",
    "[user-defined error metrics](#custom-metrics), if any). The resulting CSV file\n",
    "can be used to pick problematic layers with large quantization error metrics.\n",
    "\n",
    "With pandas or other data processing libraries, we can inspect detailed\n",
    "per-layer error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:48.015763Z",
     "iopub.status.busy": "2022-10-20T13:30:48.015054Z",
     "iopub.status.idle": "2022-10-20T13:30:48.042182Z",
     "shell.execute_reply": "2022-10-20T13:30:48.041537Z"
    },
    "id": "XUcSqYFGQb-f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_name</th>\n",
       "      <th>tensor_idx</th>\n",
       "      <th>num_elements</th>\n",
       "      <th>stddev</th>\n",
       "      <th>mean_error</th>\n",
       "      <th>max_abs_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>scale</th>\n",
       "      <th>zero_point</th>\n",
       "      <th>tensor_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUL</td>\n",
       "      <td>227</td>\n",
       "      <td>150528.0</td>\n",
       "      <td>2.162354e-03</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>-128</td>\n",
       "      <td>predict/hub_input/Mul;predict/hub_input/Mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUB</td>\n",
       "      <td>231</td>\n",
       "      <td>150528.0</td>\n",
       "      <td>3.170321e-08</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>-1</td>\n",
       "      <td>predict/hub_input/Sub;predict/hub_input/Sub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONV_2D</td>\n",
       "      <td>235</td>\n",
       "      <td>200704.0</td>\n",
       "      <td>4.148779e-02</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.102274</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.142475</td>\n",
       "      <td>-30</td>\n",
       "      <td>predict/MobilenetV3/Conv/BatchNorm/FusedBatchN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARD_SWISH</td>\n",
       "      <td>239</td>\n",
       "      <td>200704.0</td>\n",
       "      <td>2.981238e-02</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.089297</td>\n",
       "      <td>-124</td>\n",
       "      <td>predict/MobilenetV3/Conv/hard_swish/mul_1;pred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEPTHWISE_CONV_2D</td>\n",
       "      <td>243</td>\n",
       "      <td>50176.0</td>\n",
       "      <td>2.176653e-01</td>\n",
       "      <td>-0.022613</td>\n",
       "      <td>0.723893</td>\n",
       "      <td>0.047961</td>\n",
       "      <td>0.508746</td>\n",
       "      <td>-128</td>\n",
       "      <td>predict/MobilenetV3/expanded_conv/depthwise/Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             op_name  tensor_idx  num_elements        stddev  mean_error  \\\n",
       "0                MUL         227      150528.0  2.162354e-03   -0.000002   \n",
       "1                SUB         231      150528.0  3.170321e-08    0.003922   \n",
       "2            CONV_2D         235      200704.0  4.148779e-02    0.000216   \n",
       "3         HARD_SWISH         239      200704.0  2.981238e-02   -0.000470   \n",
       "4  DEPTHWISE_CONV_2D         243       50176.0  2.176653e-01   -0.022613   \n",
       "\n",
       "   max_abs_error  mean_squared_error     scale  zero_point  \\\n",
       "0       0.003922            0.000005  0.007843        -128   \n",
       "1       0.003922            0.000015  0.007843          -1   \n",
       "2       0.102274            0.001726  0.142475         -30   \n",
       "3       0.045249            0.000893  0.089297        -124   \n",
       "4       0.723893            0.047961  0.508746        -128   \n",
       "\n",
       "                                         tensor_name  \n",
       "0        predict/hub_input/Mul;predict/hub_input/Mul  \n",
       "1        predict/hub_input/Sub;predict/hub_input/Sub  \n",
       "2  predict/MobilenetV3/Conv/BatchNorm/FusedBatchN...  \n",
       "3  predict/MobilenetV3/Conv/hard_swish/mul_1;pred...  \n",
       "4  predict/MobilenetV3/expanded_conv/depthwise/Re...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "layer_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7C_oHxWFOV6M"
   },
   "source": [
    "### Step 3. Data analysis\n",
    "\n",
    "There are various ways to analyze the resulting. First, let's add some useful\n",
    "metrics derived from the debugger's outputs. (`scale` means the quantization\n",
    "scale factor for each tensor.)\n",
    "\n",
    "*   Range (`256 / scale`)\n",
    "*   RMSE / scale (`sqrt(mean_squared_error) / scale`)\n",
    "\n",
    "The `RMSE / scale` is close to `1 / sqrt(12)` (~ 0.289) when quantized\n",
    "distribution is similar to the original float distribution, indicating a good\n",
    "quantized model. The larger the value is, it's more likely for the layer not\n",
    "being quantized well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:48.046450Z",
     "iopub.status.busy": "2022-10-20T13:30:48.045770Z",
     "iopub.status.idle": "2022-10-20T13:30:48.058168Z",
     "shell.execute_reply": "2022-10-20T13:30:48.057520Z"
    },
    "id": "mwviORyJN6e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_name</th>\n",
       "      <th>range</th>\n",
       "      <th>rmse/scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUL</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.276802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUB</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.499994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONV_2D</td>\n",
       "      <td>36.331013</td>\n",
       "      <td>0.291630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARD_SWISH</td>\n",
       "      <td>22.770702</td>\n",
       "      <td>0.334676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEPTHWISE_CONV_2D</td>\n",
       "      <td>129.730204</td>\n",
       "      <td>0.430470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             op_name       range  rmse/scale\n",
       "0                MUL    2.000000    0.276802\n",
       "1                SUB    2.000000    0.499994\n",
       "2            CONV_2D   36.331013    0.291630\n",
       "3         HARD_SWISH   22.770702    0.334676\n",
       "4  DEPTHWISE_CONV_2D  129.730204    0.430470"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_stats['range'] = 255.0 * layer_stats['scale']\n",
    "layer_stats['rmse/scale'] = layer_stats.apply(\n",
    "    lambda row: np.sqrt(row['mean_squared_error']) / row['scale'], axis=1)\n",
    "layer_stats[['op_name', 'range', 'rmse/scale']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:48.061772Z",
     "iopub.status.busy": "2022-10-20T13:30:48.061290Z",
     "iopub.status.idle": "2022-10-20T13:30:48.548379Z",
     "shell.execute_reply": "2022-10-20T13:30:48.547750Z"
    },
    "id": "oAAv35CdPvc4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.bar(np.arange(len(layer_stats)), layer_stats['range'])\n",
    "ax1.set_ylabel('range')\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.bar(np.arange(len(layer_stats)), layer_stats['rmse/scale'])\n",
    "ax2.set_ylabel('rmse/scale')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pqUQvRUWB3Q"
   },
   "source": [
    "There are many layers with wide ranges, and some layers that have high\n",
    "`RMSE/scale` values. Let's get the layers with high error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:48.552424Z",
     "iopub.status.busy": "2022-10-20T13:30:48.552186Z",
     "iopub.status.idle": "2022-10-20T13:30:48.561709Z",
     "shell.execute_reply": "2022-10-20T13:30:48.561084Z"
    },
    "id": "UqFsUX4_Q-cE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_name</th>\n",
       "      <th>range</th>\n",
       "      <th>rmse/scale</th>\n",
       "      <th>tensor_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MEAN</td>\n",
       "      <td>3.300810</td>\n",
       "      <td>0.771602</td>\n",
       "      <td>predict/MobilenetV3/expanded_conv_4/squeeze_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CONV_2D</td>\n",
       "      <td>2.866467</td>\n",
       "      <td>0.784422</td>\n",
       "      <td>predict/MobilenetV3/expanded_conv_4/squeeze_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>CONV_2D</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>1.011160</td>\n",
       "      <td>predict/MobilenetV3/expanded_conv_6/squeeze_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>MEAN</td>\n",
       "      <td>3.214616</td>\n",
       "      <td>1.051455</td>\n",
       "      <td>predict/MobilenetV3/expanded_conv_8/squeeze_ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    op_name     range  rmse/scale  \\\n",
       "32     MEAN  3.300810    0.771602   \n",
       "33  CONV_2D  2.866467    0.784422   \n",
       "55  CONV_2D  0.001957    1.011160   \n",
       "75     MEAN  3.214616    1.051455   \n",
       "\n",
       "                                          tensor_name  \n",
       "32  predict/MobilenetV3/expanded_conv_4/squeeze_ex...  \n",
       "33  predict/MobilenetV3/expanded_conv_4/squeeze_ex...  \n",
       "55  predict/MobilenetV3/expanded_conv_6/squeeze_ex...  \n",
       "75  predict/MobilenetV3/expanded_conv_8/squeeze_ex...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_stats[layer_stats['rmse/scale'] > 0.7][[\n",
    "    'op_name', 'range', 'rmse/scale', 'tensor_name'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHeALFTGWl_e"
   },
   "source": [
    "With these layers, you can try selective quantization to see if not quantizing\n",
    "those layers improves model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:48.565327Z",
     "iopub.status.busy": "2022-10-20T13:30:48.564932Z",
     "iopub.status.idle": "2022-10-20T13:30:48.568587Z",
     "shell.execute_reply": "2022-10-20T13:30:48.568005Z"
    },
    "id": "cvdkjsbwYC6e"
   },
   "outputs": [],
   "source": [
    "suspected_layers = list(\n",
    "    layer_stats[layer_stats['rmse/scale'] > 0.7]['tensor_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6RQw9JobOTR"
   },
   "source": [
    "In addition to these, skipping quantization for the first few layers also helps\n",
    "improving quantized model's quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:48.572427Z",
     "iopub.status.busy": "2022-10-20T13:30:48.572054Z",
     "iopub.status.idle": "2022-10-20T13:30:48.575582Z",
     "shell.execute_reply": "2022-10-20T13:30:48.575022Z"
    },
    "id": "ikF2bp6NZcXN"
   },
   "outputs": [],
   "source": [
    "suspected_layers.extend(list(layer_stats[:5]['tensor_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DfT78w6W6Li"
   },
   "source": [
    "## Selective Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pubC-01cGEH"
   },
   "source": [
    "Selective quantization skips quantization for some nodes, so that the\n",
    "calculation can happen in the original floating-point domain. When correct\n",
    "layers are skipped, we can expect some model quality recovery at the cost of\n",
    "increased latency and model size.\n",
    "\n",
    "However, if you're planning to run quantized models on integer-only accelerators\n",
    "(e.g. Hexagon DSP, EdgeTPU), selective quantization would cause fragmentation of\n",
    "the model and would result in slower inference latency mainly caused by data\n",
    "transfer cost between CPU and those accelerators. To prevent this, you can\n",
    "consider running\n",
    "[quantization aware training](https://www.tensorflow.org/model_optimization/guide/quantization/training)\n",
    "to keep all the layers in integer while preserving the model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQFBfR7YW-oh"
   },
   "source": [
    "Quantization debugger's option accepts `denylisted_nodes` and `denylisted_ops`\n",
    "options for skipping quantization for specific layers, or all instances of\n",
    "specific ops. Using `suspected_layers` we prepared from the previous step, we\n",
    "can use quantization debugger to get a selectively quantized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:30:48.579742Z",
     "iopub.status.busy": "2022-10-20T13:30:48.579211Z",
     "iopub.status.idle": "2022-10-20T13:31:03.484720Z",
     "shell.execute_reply": "2022-10-20T13:31:03.483903Z"
    },
    "id": "K5KD0JAEbpsv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnh4uk9gp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnh4uk9gp/assets\n",
      "/home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-02-14 14:28:15.517082: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-02-14 14:28:15.517108: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-02-14 14:28:15.517299: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpnh4uk9gp\n",
      "2023-02-14 14:28:15.528689: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-02-14 14:28:15.528718: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpnh4uk9gp\n",
      "2023-02-14 14:28:15.563578: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-02-14 14:28:15.787251: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpnh4uk9gp\n",
      "2023-02-14 14:28:15.861552: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 344252 microseconds.\n",
      "2023-02-14 14:28:16.248950: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2116] Estimated count of arithmetic ops: 115.112 M  ops, equivalently 57.556 M  MACs\n",
      "2023-02-14 14:28:16.313874: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-02-14 14:28:16.314312: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "2023-02-14 14:28:19.379990: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2116] Estimated count of arithmetic ops: 217.892 M  ops, equivalently 108.946 M  MACs\n"
     ]
    }
   ],
   "source": [
    "debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
    "    denylisted_nodes=suspected_layers)\n",
    "debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "    converter=converter,\n",
    "    debug_dataset=representative_dataset(ds),\n",
    "    debug_options=debug_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:31:03.489526Z",
     "iopub.status.busy": "2022-10-20T13:31:03.488678Z",
     "iopub.status.idle": "2022-10-20T13:31:06.218091Z",
     "shell.execute_reply": "2022-10-20T13:31:06.217292Z"
    },
    "id": "pfj9gzv4b7h4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "2023-02-14 14:30:07.628801: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2116] Estimated count of arithmetic ops: 115.112 M  ops, equivalently 57.556 M  MACs\n",
      "2023-02-14 14:30:07.639183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-02-14 14:30:07.639535: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 accuracy (quantized): 65.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 14:30:08.420209: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-02-14 14:30:08.420520: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2981624"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selective_quantized_model = debugger.get_nondebug_quantized_model()\n",
    "eval_tflite(selective_quantized_model, ds)\n",
    "open('selectiveq.tflite', \"wb\").write(selective_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RkfMYSHdtZy"
   },
   "source": [
    "The accuracy is still lower compared to the original float model, but we have\n",
    "notable improvement from the whole quantized model by skipping quantization for\n",
    "~10 layers out of 111 layers.\n",
    "\n",
    "You can also try to not quantized all ops in the same class. For example, to\n",
    "skip quantization for all mean ops, you can pass `MEAN` to `denylisted_ops`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:31:06.222084Z",
     "iopub.status.busy": "2022-10-20T13:31:06.221806Z",
     "iopub.status.idle": "2022-10-20T13:31:20.540261Z",
     "shell.execute_reply": "2022-10-20T13:31:20.539481Z"
    },
    "id": "ruUoP7SgcLpO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmpfs/tmp/tmp6ypc8qhf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmpfs/tmp/tmp6ypc8qhf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmpfs/src/tf_docs_env/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 13:31:14.254986: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-20 13:31:14.255037: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
    "    denylisted_ops=['MEAN'])\n",
    "debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "    converter=converter,\n",
    "    debug_dataset=representative_dataset(ds),\n",
    "    debug_options=debug_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:31:20.544733Z",
     "iopub.status.busy": "2022-10-20T13:31:20.544448Z",
     "iopub.status.idle": "2022-10-20T13:31:23.363244Z",
     "shell.execute_reply": "2022-10-20T13:31:23.362466Z"
    },
    "id": "oY6kb5g_cO4H"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 accuracy (quantized): 51.00%\n"
     ]
    }
   ],
   "source": [
    "selective_quantized_model = debugger.get_nondebug_quantized_model()\n",
    "eval_tflite(selective_quantized_model, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xa8488TeAyx-"
   },
   "source": [
    "With these techniques, we are able to improve the quantized MobileNet V3 model\n",
    "accuracy. Next we'll explore advanced techniques to improve the model accuracy\n",
    "even more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZD75cY9PUb2u"
   },
   "source": [
    "## Advanced usages\n",
    "\n",
    "Whith following features, you can further customize your debugging pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVj9yrQoUfGo"
   },
   "source": [
    "### Custom metrics\n",
    "\n",
    "By default, the quantization debugger emits five metrics for each float-quant\n",
    "difference: tensor size, standard deviation, mean error, max absolute error, and\n",
    "mean squared error. You can add more custom metrics by passing them to options.\n",
    "For each metrics, the result should be a single float value and the resulting\n",
    "metric will be an average of metrics from all examples.\n",
    "\n",
    "*   `layer_debug_metrics`: calculate metric based on diff for each op outputs\n",
    "    from float and quantized op outputs.\n",
    "*   `layer_direct_compare_metrics`: rather than getting diff only, this will\n",
    "    calculate metric based on raw float and quantized tensors, and its\n",
    "    quantization parameters (scale, zero point)\n",
    "*   `model_debug_metrics`: **only used when `float_model_(path|content)` is\n",
    "    passed** to the debugger. In addition to the op-level metrics, final layer\n",
    "    output is compared to the reference output from the original float model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:31:23.368109Z",
     "iopub.status.busy": "2022-10-20T13:31:23.367467Z",
     "iopub.status.idle": "2022-10-20T13:31:46.781371Z",
     "shell.execute_reply": "2022-10-20T13:31:46.780602Z"
    },
    "id": "WqmRQSxoVVwu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmpfs/tmp/tmp9w8zlypq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmpfs/tmp/tmp9w8zlypq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 13:31:31.326115: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-20 13:31:31.326168: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmpfs/tmp/tmprs4i0_bf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmpfs/tmp/tmprs4i0_bf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmpfs/src/tf_docs_env/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2022-10-20 13:31:40.543706: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-20 13:31:40.543753: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "debug_options = tf.lite.experimental.QuantizationDebugOptions(\n",
    "    layer_debug_metrics={\n",
    "        'mean_abs_error': (lambda diff: np.mean(np.abs(diff)))\n",
    "    },\n",
    "    layer_direct_compare_metrics={\n",
    "        'correlation':\n",
    "            lambda f, q, s, zp: (np.corrcoef(f.flatten(),\n",
    "                                             (q.flatten() - zp) / s)[0, 1])\n",
    "    },\n",
    "    model_debug_metrics={\n",
    "        'argmax_accuracy': (lambda f, q: np.mean(np.argmax(f) == np.argmax(q)))\n",
    "    })\n",
    "\n",
    "debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "    converter=converter,\n",
    "    debug_dataset=representative_dataset(ds),\n",
    "    debug_options=debug_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:31:46.784928Z",
     "iopub.status.busy": "2022-10-20T13:31:46.784642Z",
     "iopub.status.idle": "2022-10-20T13:32:02.697765Z",
     "shell.execute_reply": "2022-10-20T13:32:02.696943Z"
    },
    "id": "PVQ4nEicXz2l"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmpfs/src/tf_docs_env/lib/python3.9/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmpfs/src/tf_docs_env/lib/python3.9/site-packages/tensorflow/lite/tools/optimize/debugging/python/debugger.py:382: RuntimeWarning: Mean of empty slice\n",
      "  metrics[metric_name] = np.nanmean(metrics[metric_name])\n"
     ]
    }
   ],
   "source": [
    "debugger.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:32:02.702981Z",
     "iopub.status.busy": "2022-10-20T13:32:02.702226Z",
     "iopub.status.idle": "2022-10-20T13:32:02.720747Z",
     "shell.execute_reply": "2022-10-20T13:32:02.720048Z"
    },
    "id": "dfKA90csX9UL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_name</th>\n",
       "      <th>mean_abs_error</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>CONV_2D</td>\n",
       "      <td>1.890278e-02</td>\n",
       "      <td>0.007164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>HARD_SWISH</td>\n",
       "      <td>5.650395e-03</td>\n",
       "      <td>0.591051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>AVERAGE_POOL_2D</td>\n",
       "      <td>4.777645e-08</td>\n",
       "      <td>0.003867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>CONV_2D</td>\n",
       "      <td>2.027273e-02</td>\n",
       "      <td>0.997327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>RESHAPE</td>\n",
       "      <td>1.335906e-07</td>\n",
       "      <td>0.997489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             op_name  mean_abs_error  correlation\n",
       "106          CONV_2D    1.890278e-02     0.007164\n",
       "107       HARD_SWISH    5.650395e-03     0.591051\n",
       "108  AVERAGE_POOL_2D    4.777645e-08     0.003867\n",
       "109          CONV_2D    2.027273e-02     0.997327\n",
       "110          RESHAPE    1.335906e-07     0.997489"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUSTOM_RESULTS_FILE = '/tmp/debugger_results.csv'\n",
    "with open(CUSTOM_RESULTS_FILE, 'w') as f:\n",
    "  debugger.layer_statistics_dump(f)\n",
    "\n",
    "custom_layer_stats = pd.read_csv(CUSTOM_RESULTS_FILE)\n",
    "custom_layer_stats[['op_name', 'mean_abs_error', 'correlation']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qqq30oWsZF5b"
   },
   "source": [
    "The result of `model_debug_metrics` can be separately seen from\n",
    "`debugger.model_statistics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:32:02.724736Z",
     "iopub.status.busy": "2022-10-20T13:32:02.724140Z",
     "iopub.status.idle": "2022-10-20T13:32:02.728806Z",
     "shell.execute_reply": "2022-10-20T13:32:02.728086Z"
    },
    "id": "wrXlmzEHYhQ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'argmax_accuracy': 0.38}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debugger.model_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqJBLIsoUyIg"
   },
   "source": [
    "### Using (internal) mlir_quantize API to access in-depth features\n",
    "\n",
    "Note: Some features in the folowing section,\n",
    "`TFLiteConverter._experimental_calibrate_only` and `converter.mlir_quantize` are\n",
    "experimental internal APIs, and subject to change in a non-backward compatible\n",
    "way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:32:02.732759Z",
     "iopub.status.busy": "2022-10-20T13:32:02.732233Z",
     "iopub.status.idle": "2022-10-20T13:32:02.735542Z",
     "shell.execute_reply": "2022-10-20T13:32:02.734828Z"
    },
    "id": "VJm66Cz-XpeF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.lite.python import convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2krUVzpiUp3u"
   },
   "source": [
    "#### Whole model verify mode\n",
    "\n",
    "The default behavior for the debug model generation is per-layer verify. In this\n",
    "mode, the input for float and quantize op pair is from the same source (previous\n",
    "quantized op). Another mode is whole-model verify, where the float and quantize\n",
    "models are separated. This mode would be useful to observe how the error is\n",
    "being propagated down the model. To enable, `enable_whole_model_verify=True` to\n",
    "`convert.mlir_quantize` while generating the debug model manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:32:02.739502Z",
     "iopub.status.busy": "2022-10-20T13:32:02.738981Z",
     "iopub.status.idle": "2022-10-20T13:32:16.885050Z",
     "shell.execute_reply": "2022-10-20T13:32:16.884313Z"
    },
    "id": "5zykINDlVLSg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmpfs/tmp/tmp3g631ley/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmpfs/tmp/tmp3g631ley/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmpfs/src/tf_docs_env/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 13:32:11.224748: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-10-20 13:32:11.224798: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.representative_dataset = representative_dataset(ds)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter._experimental_calibrate_only = True\n",
    "calibrated_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:32:16.889347Z",
     "iopub.status.busy": "2022-10-20T13:32:16.888927Z",
     "iopub.status.idle": "2022-10-20T13:32:17.468310Z",
     "shell.execute_reply": "2022-10-20T13:32:17.467569Z"
    },
    "id": "eqvXlEiFXfSu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "# Note that enable_numeric_verify and enable_whole_model_verify are set.\n",
    "quantized_model = convert.mlir_quantize(\n",
    "    calibrated_model,\n",
    "    enable_numeric_verify=True,\n",
    "    enable_whole_model_verify=True)\n",
    "debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "    quant_debug_model_content=quantized_model,\n",
    "    debug_dataset=representative_dataset(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQ6TFsXQVHMe"
   },
   "source": [
    "#### Selective quantization from an already calibrated model\n",
    "\n",
    "You can directly call `convert.mlir_quantize` to get the selective quantized\n",
    "model from already calibrated model. This would be particularly useful when you\n",
    "want to calibrate the model once, and experiment with various denylist\n",
    "combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:32:17.481438Z",
     "iopub.status.busy": "2022-10-20T13:32:17.481159Z",
     "iopub.status.idle": "2022-10-20T13:32:20.133795Z",
     "shell.execute_reply": "2022-10-20T13:32:20.132981Z"
    },
    "id": "ZCS-Fa9lbdc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 accuracy (quantized): 65.00%\n"
     ]
    }
   ],
   "source": [
    "selective_quantized_model = convert.mlir_quantize(\n",
    "    calibrated_model, denylisted_nodes=suspected_layers)\n",
    "eval_tflite(selective_quantized_model, ds)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Eq_8T2oauIED"
   ],
   "name": "quantization_debugger.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Quantize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3a07a8b495e35acd8285d5b15102e67f59870bcd0ea6b5dc22aa69117eb6599"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
