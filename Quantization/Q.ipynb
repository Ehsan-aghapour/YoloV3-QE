{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KimMZUVqcJ8_"
   },
   "source": [
    "##### Copyright 2021 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlWzg1D9_EhW"
   },
   "source": [
    "# Inspecting Quantization Errors with Quantization Debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLoHL19yb-a0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/performance/quantization_debugger\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorflow/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTEEzJWo_iZ_"
   },
   "source": [
    "### Setup\n",
    "\n",
    "This section prepares libraries, MobileNet v3 model, and test dataset of 100\n",
    "images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:29:24.761151Z",
     "iopub.status.busy": "2022-10-20T13:29:24.760694Z",
     "iopub.status.idle": "2022-10-20T13:29:56.104175Z",
     "shell.execute_reply": "2022-10-20T13:29:56.103267Z"
    },
    "id": "l7epUDUP_6qo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ehsan/anaconda3/bin/jupytext\", line 8, in <module>\n",
      "    sys.exit(jupytext())\n",
      "  File \"/home/ehsan/anaconda3/lib/python3.8/site-packages/jupytext/cli.py\", line 488, in jupytext\n",
      "    exit_code += jupytext_single_file(nb_file, args, log)\n",
      "  File \"/home/ehsan/anaconda3/lib/python3.8/site-packages/jupytext/cli.py\", line 504, in jupytext_single_file\n",
      "    raise ValueError(msg)\n",
      "ValueError: Missing notebook path. Maybe you mean 'jupytext --sync Q.ipynb' ?\n",
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tf-nightly in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (2.13.0.dev20230214)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (0.30.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (1.14.1)\n",
      "Requirement already satisfied: packaging in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (23.0)\n",
      "Requirement already satisfied: tf-estimator-nightly~=2.13.0.dev in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (2.13.0.dev2023021409)\n",
      "Requirement already satisfied: keras-nightly~=2.13.0.dev in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (2.13.0.dev2023021408)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (15.0.6.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (0.4.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (1.51.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (2.0.7)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (2.2.0)\n",
      "Requirement already satisfied: tb-nightly~=2.13.0.a in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (2.13.0a20230213)\n",
      "Requirement already satisfied: setuptools in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (65.6.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (3.8.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (1.23.5)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tf-nightly) (4.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from astunparse>=1.6.0->tf-nightly) (0.37.1)\n",
      "Requirement already satisfied: scipy>=1.5 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from jax>=0.3.15->tf-nightly) (1.10.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tb-nightly~=2.13.0.a->tf-nightly) (2.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tb-nightly~=2.13.0.a->tf-nightly) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tb-nightly~=2.13.0.a->tf-nightly) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tb-nightly~=2.13.0.a->tf-nightly) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tb-nightly~=2.13.0.a->tf-nightly) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tb-nightly~=2.13.0.a->tf-nightly) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from tb-nightly~=2.13.0.a->tf-nightly) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.13.0.a->tf-nightly) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.13.0.a->tf-nightly) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.13.0.a->tf-nightly) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.13.0.a->tf-nightly) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.13.0.a->tf-nightly) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.13.0.a->tf-nightly) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.13.0.a->tf-nightly) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from requests<3,>=2.21.0->tb-nightly~=2.13.0.a->tf-nightly) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from werkzeug>=1.0.1->tb-nightly~=2.13.0.a->tf-nightly) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.13.0.a->tf-nightly) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.13.0.a->tf-nightly) (3.2.2)\n",
      "Requirement already satisfied: pandas in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (3.6.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ehsan/anaconda3/envs/Quantize/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert --to script Q.ipynb\n",
    "!jupytext --set-formats ipynb,py Q.ipynb --sync\n",
    "# Quantization debugger is available from TensorFlow 2.7.0\n",
    "!pip uninstall -y tensorflow\n",
    "!pip install tf-nightly\n",
    "#!pip install tensorflow_datasets --upgrade  # imagenet_v2 needs latest checksum\n",
    "#!pip install tensorflow_hub\n",
    "\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-20T13:29:56.108833Z",
     "iopub.status.busy": "2022-10-20T13:29:56.108564Z",
     "iopub.status.idle": "2022-10-20T13:29:58.828751Z",
     "shell.execute_reply": "2022-10-20T13:29:58.828049Z"
    },
    "id": "LLsgiUZe_hIa",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "#import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.lite.python import convert\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "server=0\n",
    "\n",
    "p=\"/home/ehsan/UvA/Accuracy/Keras/Yolov3/\"\n",
    "p_server=\"/home/ehsan/Accuracy/\"\n",
    "if server:\n",
    "    p=p_server\n",
    "data_dir = p+\"Dataset/val2017\"\n",
    "image_size = (608, 608)\n",
    "N=300\n",
    "\n",
    "\n",
    "resdir='Yolo_files/'\n",
    "ModelName=resdir+'Yolov3.h5'\n",
    "QuantizedName=resdir+'YoloV3_quztized.tflite'\n",
    "QSelectiveName=resdir+'YoloV3_selective_quztized.tflite'\n",
    "UQSelectiveName=resdir+'YoloV3_selective_unquztized.tflite'\n",
    "RESULTS_FILE = resdir+'yolov3_debugger_results.csv'\n",
    "RESULTS_FILE_Propogate = resdir+'yolov3_debugger_propogate_results.csv'\n",
    "DebuggerName=resdir+'Debugger_Yolov3.pkl'\n",
    "DebuggerPropogateName=resdir+'Debugger_Yolov3_propogation.pkl'\n",
    "CalibratedName=resdir+'YoloV3_calibrated.tflite'\n",
    "\n",
    "\n",
    "# Define the input shape and data type\n",
    "input_shape = (1, 608, 608, 3)\n",
    "input_dtype = tf.float32\n",
    "\n",
    "# Define the output shape and data type\n",
    "output_shape = (1,)\n",
    "output_dtype = tf.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def load_model(m=ModelName):\n",
    "    model = tf.keras.models.load_model(m)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to load and preprocess each image\n",
    "def preprocess_image(file_path):\n",
    "\t# Load the image\n",
    "\timage = tf.io.read_file(file_path)\n",
    "\t# Decode the JPEG image to a tensor\n",
    "\timage = tf.image.decode_jpeg(image, channels=3)\n",
    "\t# Resize the image to the desired size\n",
    "\timage = tf.image.resize(image, image_size)\n",
    "\t# Normalize the pixel values to the range [0, 1]\n",
    "\timage = image / 255.0\n",
    "\treturn image\n",
    "\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((images))\n",
    "#train_dataset=train_dataset.map(process_image)\n",
    "def load_dataset():\n",
    "\t# Create a list of file paths to the JPEG images\n",
    "\tfile_paths = tf.data.Dataset.list_files(data_dir + \"/*.jpg\")\n",
    "\t# Use the map() method to apply the preprocessing function to each image\n",
    "\tdataset = file_paths.map(preprocess_image)\n",
    "\t#dataset = dataset.map(lambda x: {'input_1': x})\n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def gen_rep():\n",
    "    train_dataset=prepare_dataset()    \n",
    "    representative_dataset = train_dataset.take(100).batch(1)\n",
    "    return representative_dataset\n",
    "    \n",
    "def representative_dataset(dataset):\n",
    "\tdef _data_gen():\n",
    "\t\tfor data in dataset.batch(1):\n",
    "\t\t\tyield [data['image']]\n",
    "\treturn _data_gen\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#representative_dataset = dataset.take(300).batch(1)\n",
    "def rep(_dataset,n=N):\n",
    "    def representative_dataset():\n",
    "        for img in _dataset.take(n):\n",
    "            #img = tf.cast(img, tf.float32)\n",
    "            yield {'input_1': np.array([img])}\n",
    "            #yield np.array(img)\n",
    "    #return tf.data.Dataset.from_generator(representative_dataset, {'input_1': tf.float32}, {'input_1': tf.TensorShape([1, None, None, 3])})\n",
    "    return representative_dataset\n",
    "\n",
    "def rep2(_dataset,n=N):\n",
    "    def representative_dataset():\n",
    "        for img in _dataset.take(n):\n",
    "            #img = tf.cast(img, tf.float32)\n",
    "            \n",
    "            #img = tf.expand_dims(img, axis=0)\n",
    "            #yield [np.array(img)]\n",
    "            \n",
    "            yield [np.array([img])]\n",
    "    return representative_dataset\n",
    "\n",
    "def rep3(_dataset,n=N):\n",
    "    for img in _dataset.take(n):\n",
    "        yield [np.array([img])]\n",
    "\n",
    "def quantize(model,_dataset,name=QuantizedName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"quantization...\\n\")\n",
    "    if (os.path.isfile(QuantizedName)):\n",
    "        print(f\"loading existed {QuantizedName}\")\n",
    "        with open(name, 'rb') as f:\n",
    "            quantized_model=f.read()\n",
    "    else:\n",
    "        print(f'quantization: producing file {QuantizedName}')\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.representative_dataset = tf.lite.RepresentativeDataset(rep(_dataset))\n",
    "        converter.representative_dataset = rep2(_dataset,N)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        quantized_model = converter.convert()\n",
    "        open(name, \"wb\").write(quantized_model)\n",
    "    return quantized_model\n",
    "\n",
    "def explore(model,_dataset,debugger_name=DebuggerName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"explore...\\n\")\n",
    "    if (os.path.isfile(DebuggerName)):\n",
    "        print(f'loading existed file {DebuggerName}')\n",
    "        with open(debugger_name, 'rb') as f:\n",
    "            debugger=pickle.load(f)\n",
    "    elif (os.path.isfile(RESULTS_FILE)):\n",
    "        print(f'explore not required, existed file {RESULTS_FILE}')\n",
    "        return \n",
    "    else:\n",
    "        print(f'explore: producing file {DebuggerName}...')\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        #converter.representative_dataset = rep2(_dataset,N)\n",
    "        converter.representative_dataset = tf.lite.RepresentativeDataset(rep2(_dataset))\n",
    "        # my_debug_dataset should have the same format as my_representative_dataset\n",
    "        #debug_dataset=tf.lite.RepresentativeDataset(rep3(_dataset))\n",
    "        debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "            converter=converter, debug_dataset=rep2(_dataset))\n",
    "        #with open(debugger_name, 'wb') as f:\n",
    "        #    pickle.dump(debugger, f)\n",
    "\n",
    "    return debugger\n",
    "\n",
    "def run_debugger(debugger,res_file):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"run debugger...\\n\")\n",
    "    if not (os.path.isfile(res_file)):\n",
    "        print(f'run_debugger: producing file {res_file}')\n",
    "        debugger.run()\n",
    "        with open(res_file, 'w') as f:\n",
    "            debugger.layer_statistics_dump(f)\n",
    "    else:\n",
    "        print(f'run_debugger: file is existed; {res_file}')\n",
    "\n",
    "def Analyze(res_file,t=-.33):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"Analyze...\\n\")\n",
    "    layer_stats = pd.read_csv(res_file)\n",
    "    layer_stats.head()\n",
    "    layer_stats['range'] = 255.0 * layer_stats['scale']\n",
    "    layer_stats['rmse/scale'] = layer_stats.apply(\n",
    "        lambda row: np.sqrt(row['mean_squared_error']) / row['scale'], axis=1)\n",
    "    layer_stats[['op_name', 'range', 'rmse/scale']].head()\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.bar(np.arange(len(layer_stats)), layer_stats['range'])\n",
    "    ax1.set_ylabel('range')\n",
    "    ax2 = plt.subplot(122)\n",
    "    ax2.bar(np.arange(len(layer_stats)), layer_stats['rmse/scale'])\n",
    "    ax2.set_ylabel('rmse/scale')\n",
    "    plt.show()\n",
    "    #print(layer_stats[layer_stats['rmse/scale'] > t][['op_name', 'range', 'rmse/scale', 'tensor_name']])\n",
    "    layer_stats.to_csv(res_file)\n",
    "\n",
    "def selective_quantize(model,_dataset,t=0.33):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"selective quantization...\\n\")\n",
    "    if (os.path.isfile(QSelectiveName)):\n",
    "        print(f'selective quantization: loading existed file {QSelectiveName}')\n",
    "        with open(QSelectiveName, \"rb\") as f:\n",
    "            selective_quantized_model=f.read()\n",
    "    else:\n",
    "        print(f'selective_quatize: producing file {QSelectiveName}')\n",
    "        layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "        suspected_layers = list(\n",
    "            layer_stats[layer_stats['rmse/scale'] > t]['tensor_name'])\n",
    "        suspected_layers.extend(list(layer_stats[:5]['tensor_name']))\n",
    "\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = rep(_dataset,N)\n",
    "        debug_options = tf.lite.experimental.QuantizationDebugOptions(denylisted_nodes=suspected_layers)\n",
    "        debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "            converter=converter,debug_dataset=rep(_dataset,N),debug_options=debug_options)\n",
    "        selective_quantized_model = debugger.get_nondebug_quantized_model()\n",
    "        open(QSelectiveName, \"wb\").write(selective_quantized_model)\n",
    "    return selective_quantized_model\n",
    "\n",
    "def calibrate(model,_dataset,name=CalibratedName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"calibrate...\\n\")\n",
    "    if (os.path.isfile(CalibratedName)):\n",
    "        print(f'calibrate: loading existing file {CalibratedName}')\n",
    "        with open(name, 'rb') as f:\n",
    "            calibrated_model = f.read()\n",
    "    else:\n",
    "        print(f\"calibrate producing file {CalibratedName}\")\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.representative_dataset = rep2(_dataset)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter._experimental_calibrate_only = True\n",
    "        converter.inference_input_type = input_dtype\n",
    "        converter.inference_output_type = output_dtype\n",
    "        converter.inference_input_shape = input_shape\n",
    "        converter.inference_output_shape = output_shape\n",
    "        calibrated_model = converter.convert()\n",
    "        open(name, \"wb\").write(calibrated_model)\n",
    "    return calibrated_model\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def explore_propogation(calibrated_model,_dataset,debugger_name=DebuggerPropogateName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"explore propogation...\\n\")\n",
    "    if (os.path.isfile(DebuggerPropogateName)):\n",
    "        print(f'explore propogation: loading existed file {DebuggerPropogateName}')\n",
    "        with open(debugger_name, 'rb') as f:\n",
    "            debugger=pickle.load(f)\n",
    "    elif (os.path.isfile(RESULTS_FILE_Propogate)):\n",
    "        print(f'explore propogate not required, existed file {RESULTS_FILE_Propogate}')\n",
    "        return\n",
    "    else:\n",
    "        print(f\"explore_propogation: Producing file {DebuggerPropogateName}\")\n",
    "        # Note that enable_numeric_verify and enable_whole_model_verify are set.\n",
    "        quantized_model = convert.mlir_quantize(\n",
    "            calibrated_model,\n",
    "            enable_numeric_verify=True,\n",
    "            enable_whole_model_verify=True)\n",
    "        debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "            quant_debug_model_content=quantized_model,\n",
    "            debug_dataset=rep2(_dataset))\n",
    "        #with open(debugger_name, 'wb') as f:\n",
    "        #    pickle.dump(debugger, f)\n",
    "    return debugger\n",
    "\n",
    "def explore_combinations(calibrated_model,suspected_layers=[],t=0.35,name=UQSelectiveName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"explore combination...\\n\")\n",
    "    if (os.path.isfile(name)):\n",
    "        print(f'explore combinations: loading existed file {name}')\n",
    "        with open(name, 'rb') as f:\n",
    "            selective_quantized_model = f.read()\n",
    "    else:\n",
    "        print(f\"explore_combinations: producing file {name}\")\n",
    "        layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "        suspected_layers.extend(list(layer_stats[layer_stats['rmse/scale'] > t]['tensor_name']))\n",
    "        suspected_layers.extend(list(layer_stats[:10]['tensor_name']))\n",
    "        selective_quantized_model = convert.mlir_quantize(calibrated_model, denylisted_nodes=suspected_layers)\n",
    "        open(name, \"wb\").write(selective_quantized_model)\n",
    "    return selective_quantized_model\n",
    "\n",
    "'''\n",
    "def amend_input(m=CalibratedName):\n",
    "    interpreter = tf.lite.Interpreter(model_path=m)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    input_shape = input_details[0]['shape']\n",
    "    input_shape[1] = 608\n",
    "    input_shape[2] = 608\n",
    "    interpreter.resize_tensor_input(0, input_shape)\n",
    "    interpreter.allocate_tensors()\n",
    "    print(interpreter.get_input_details())\n",
    "    converter = tf.lite.TFLiteConverter.from_interpreter(interpreter)\n",
    "    #converter.allow_custom_ops = True  # If you have any custom ops in your model\n",
    "    tflite_model = converter.convert()\n",
    "    with open('modified_model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(m=ModelName)\n",
    "model.summary()\n",
    "dataset=load_dataset()\n",
    "# Print the first 5 images in the dataset\n",
    "for image in dataset.take(5):\n",
    "\tprint(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_model=calibrate(model,dataset)\n",
    "\n",
    "quantized_model=quantize(model,dataset)\n",
    "\n",
    "debugger=explore(model,dataset)\n",
    "\n",
    "\n",
    "run_debugger(debugger,RESULTS_FILE)\n",
    "Analyze(RESULTS_FILE)\n",
    "selective_quantized=selective_quantize(model,dataset)\n",
    "\n",
    "calibrated_model=calibrate(model,dataset)\n",
    "debugger=explore_propogation(calibrated_model,dataset)\n",
    "run_debugger(debugger,RESULTS_FILE_Propogate)\n",
    "Analyze(RESULTS_FILE_Propogate)\n",
    "calibrated_model=calibrate(model,dataset)\n",
    "selective_unquantized=explore_combinations(calibrated_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Eq_8T2oauIED"
   ],
   "name": "quantization_debugger.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Quantize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3a07a8b495e35acd8285d5b15102e67f59870bcd0ea6b5dc22aa69117eb6599"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
