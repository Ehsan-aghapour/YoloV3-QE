{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece1f781",
   "metadata": {
    "id": "KimMZUVqcJ8_"
   },
   "source": [
    "##### Copyright 2021 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f971d",
   "metadata": {
    "id": "BlWzg1D9_EhW"
   },
   "source": [
    "# Inspecting Quantization Errors with Quantization Debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d3dec",
   "metadata": {
    "id": "XLoHL19yb-a0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/lite/performance/quantization_debugger\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/tensorflow/tensorflow/lite/g3doc/performance/quantization_debugger.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/classification/5\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ad1b9b",
   "metadata": {
    "id": "qTEEzJWo_iZ_"
   },
   "source": [
    "### Setup\n",
    "\n",
    "This section prepares libraries, MobileNet v3 model, and test dataset of 100\n",
    "images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a462b",
   "metadata": {
    "id": "l7epUDUP_6qo"
   },
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to script Q.ipynb\n",
    "###!jupytext --set-formats ipynb,py Q.py --sync\n",
    "# Quantization debugger is available from TensorFlow 2.7.0\n",
    "!pip uninstall -y tensorflow\n",
    "!pip install tf-nightly\n",
    "#!pip install tensorflow_datasets --upgrade  # imagenet_v2 needs latest checksum\n",
    "#!pip install tensorflow_hub\n",
    "\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb352b4b",
   "metadata": {
    "id": "LLsgiUZe_hIa",
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 14:38:49.575525: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-03-09 14:38:49.623685: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-03-09 14:38:49.624446: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 14:38:50.427437: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution dir:/home/ehsan/Accuracy/YOLOV3/Evaluation\n",
      "GPU list:[]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "#import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.lite.python import convert\n",
    "import pickle\n",
    "import os\n",
    "from tensorflow.lite.python import interpreter as interpreter_wrapper\n",
    "import numpy as np\n",
    "import time\n",
    "import threading\n",
    "import pandas as pd \n",
    "import sys\n",
    "import os\n",
    "cur_dir=os.getcwd()\n",
    "sys.path.append(cur_dir+'/../Evaluation/')\n",
    "import eval_multiThread2 as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "061679ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df=pd.read_csv(\"df.csv\",index_col=0)\n",
    "df = pd.DataFrame(columns=[\"name\",\"mAP\"])\n",
    "df.loc[0]=[\"a\", 3.2]\n",
    "df.loc[1]=[\"b\", 4.1]\n",
    "df.to_csv(\"test.csv\")\n",
    "df2=pd.read_csv(\"test.csv\",index_col=0)\n",
    "df2.loc[2]=[\"c\", 5.1]\n",
    "df2\n",
    "df.loc[71]=[\"2\",3]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652680b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "server=1\n",
    "GPU=1\n",
    "\n",
    "p=\"/home/ehsan/UvA/Accuracy/Keras/\"\n",
    "p_server=\"/home/ehsan/Accuracy/\"\n",
    "if server:\n",
    "    p=p_server\n",
    "data_dir = p+\"YOLOV3/Dataset/val2017\"\n",
    "image_size = (608, 608)\n",
    "N=300\n",
    "\n",
    "\n",
    "resdir='Yolo_files/'\n",
    "ModelName=resdir+'Yolov3.h5'\n",
    "QuantizedName=resdir+'YoloV3_quztized.tflite'\n",
    "QSelectiveName=resdir+'YoloV3_selective_quztized.tflite'\n",
    "UQSelectiveName=resdir+'YoloV3_selective_unquztized.tflite'\n",
    "RESULTS_FILE = resdir+'yolov3_debugger_results.csv'\n",
    "RESULTS_FILE_ANALYZED = resdir+'yolov3_debugger_results_analyzed.csv'\n",
    "RESULTS_FILE_Propogate = resdir+'yolov3_debugger_propogate_results.csv'\n",
    "RESULTS_FILE_Propogate_ANALYZED = resdir+'yolov3_debugger_propogate_results_analyzed.csv'\n",
    "DebuggerName=resdir+'Debugger_Yolov3.pkl'\n",
    "DebuggerPropogateName=resdir+'Debugger_Yolov3_propogation.pkl'\n",
    "CalibratedName=resdir+'YoloV3_calibrated.tflite'\n",
    "\n",
    "\n",
    "# Define the input shape and data type\n",
    "input_shape = (1, 608, 608, 3)\n",
    "input_dtype = tf.float32\n",
    "\n",
    "# Define the output shape and data type\n",
    "output_shape = (1,)\n",
    "output_dtype = tf.float32\n",
    "\n",
    "if GPU:\n",
    "    #tf.debugging.set_log_device_placement(True)\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    print(physical_devices)\n",
    "    #tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1391e9",
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def load_model(m=ModelName):\n",
    "    model = tf.keras.models.load_model(m)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to load and preprocess each image\n",
    "def preprocess_image(file_path):\n",
    "    # Load the image\n",
    "    image = tf.io.read_file(file_path)\n",
    "    # Decode the JPEG image to a tensor\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    # Resize the image to the desired size\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    # Normalize the pixel values to the range [0, 1]\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((images))\n",
    "#train_dataset=train_dataset.map(process_image)\n",
    "def load_dataset():\n",
    "    # Create a list of file paths to the JPEG images\n",
    "    file_paths = tf.data.Dataset.list_files(data_dir + \"/*.jpg\")\n",
    "    # Use the map() method to apply the preprocessing function to each image\n",
    "    dataset = file_paths.map(preprocess_image)\n",
    "    #dataset = dataset.map(lambda x: {'input_1': x})\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def gen_rep():\n",
    "    train_dataset=prepare_dataset()    \n",
    "    representative_dataset = train_dataset.take(100).batch(1)\n",
    "    return representative_dataset\n",
    "    \n",
    "def representative_dataset(dataset):\n",
    "\tdef _data_gen():\n",
    "\t\tfor data in dataset.batch(1):\n",
    "\t\t\tyield [data['image']]\n",
    "\treturn _data_gen\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#representative_dataset = dataset.take(300).batch(1)\n",
    "def rep(_dataset,n=N):\n",
    "    def representative_dataset():\n",
    "        for img in _dataset.take(n):\n",
    "            #img = tf.cast(img, tf.float32)\n",
    "            yield {'input_1': np.array([img])}\n",
    "            #yield np.array(img)\n",
    "    #return tf.data.Dataset.from_generator(representative_dataset, {'input_1': tf.float32}, {'input_1': tf.TensorShape([1, None, None, 3])})\n",
    "    return representative_dataset\n",
    "\n",
    "def rep2(_dataset,n=N):\n",
    "    def representative_dataset():\n",
    "        for img in _dataset.take(n):\n",
    "            #img = tf.cast(img, tf.float32)\n",
    "            \n",
    "            #img = tf.expand_dims(img, axis=0)\n",
    "            #yield [np.array(img)]\n",
    "            \n",
    "            yield [np.array([img])]\n",
    "    return representative_dataset\n",
    "\n",
    "def rep3(_dataset,n=N):\n",
    "    for img in _dataset.take(n):\n",
    "        yield [np.array([img])]\n",
    "\n",
    "def quantize(model,_dataset,name=QuantizedName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"quantization...\\n\")\n",
    "    if False and (os.path.isfile(QuantizedName)):\n",
    "        print(f\"loading existed {QuantizedName}\")\n",
    "        with open(name, 'rb') as f:\n",
    "            quantized_model=f.read()\n",
    "    else:\n",
    "        print(f'quantization: producing file {QuantizedName}')\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.representative_dataset = tf.lite.RepresentativeDataset(rep(_dataset))\n",
    "        converter.representative_dataset = rep2(_dataset,N)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        #converter.target_spec.supported_ops = [\n",
    "        #    tf.lite.OpsSet.TFLITE_BUILTINS_INT8_GPU \n",
    "        #]\n",
    "        #converter.inference_input_type = tf.uint8\n",
    "        #converter.inference_output_type = tf.uint8\n",
    "        converter.experimental_enable_resource_variables = True\n",
    "        converter.target_spec.supported_types = [tf.int8]\n",
    "\n",
    "        quantized_model = converter.convert()\n",
    "        open(name, \"wb\").write(quantized_model)\n",
    "    return quantized_model\n",
    "\n",
    "def explore(model,_dataset,debugger_name=DebuggerName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"explore...\\n\")\n",
    "    if (os.path.isfile(DebuggerName)):\n",
    "        print(f'loading existed file {DebuggerName}')\n",
    "        with open(debugger_name, 'rb') as f:\n",
    "            debugger=pickle.load(f)\n",
    "    elif (os.path.isfile(RESULTS_FILE)):\n",
    "        print(f'explore not required, existed file {RESULTS_FILE}')\n",
    "        return \n",
    "    else:\n",
    "        print(f'explore: producing file {DebuggerName}...')\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        #converter.representative_dataset = rep2(_dataset,N)\n",
    "        converter.representative_dataset = tf.lite.RepresentativeDataset(rep2(_dataset))\n",
    "        # my_debug_dataset should have the same format as my_representative_dataset\n",
    "        #debug_dataset=tf.lite.RepresentativeDataset(rep3(_dataset))\n",
    "        debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "            converter=converter, debug_dataset=rep2(_dataset))\n",
    "        #with open(debugger_name, 'wb') as f:\n",
    "        #    pickle.dump(debugger, f)\n",
    "\n",
    "    return debugger\n",
    "\n",
    "def run_debugger(debugger,res_file):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"run debugger...\\n\")\n",
    "    if not (os.path.isfile(res_file)):\n",
    "        print(f'run_debugger: producing file {res_file}')\n",
    "        debugger.run()\n",
    "        with open(res_file, 'w') as f:\n",
    "            debugger.layer_statistics_dump(f)\n",
    "    else:\n",
    "        print(f'run_debugger: file is existed; {res_file}')\n",
    "\n",
    "def Analyze(res_file=RESULTS_FILE_ANALYZED,t=-.33):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"Analyze...\\n\")\n",
    "    layer_stats = pd.read_csv(res_file)\n",
    "    layer_stats.head()\n",
    "    layer_stats['range'] = 255.0 * layer_stats['scale']\n",
    "    layer_stats['rmse/scale'] = layer_stats.apply(\n",
    "        lambda row: np.sqrt(row['mean_squared_error']) / row['scale'], axis=1)\n",
    "    layer_stats[['op_name', 'range', 'rmse/scale']].head()\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.bar(np.arange(len(layer_stats)), layer_stats['range'])\n",
    "    ax1.set_ylabel('range')\n",
    "    ax2 = plt.subplot(122)\n",
    "    ax2.bar(np.arange(len(layer_stats)), layer_stats['rmse/scale'])\n",
    "    ax2.set_ylabel('rmse/scale')\n",
    "    plt.show()\n",
    "    #print(layer_stats[layer_stats['rmse/scale'] > t][['op_name', 'range', 'rmse/scale', 'tensor_name']])\n",
    "    layer_stats.to_csv(res_file,sep=',')\n",
    "\n",
    "def selective_quantize(model,_dataset,t=0.33, p=0.5):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"selective quantization...\\n\")\n",
    "    caching=False\n",
    "    if (os.path.isfile(QSelectiveName)) and caching:\n",
    "        print(f'selective quantization: loading existed file {QSelectiveName}')\n",
    "        with open(QSelectiveName, \"rb\") as f:\n",
    "            selective_quantized_model=f.read()\n",
    "    else:\n",
    "        print(f'selective_quatize: producing file {QSelectiveName}')\n",
    "        layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "        suspected_layers = list(layer_stats[layer_stats['rmse/scale'] > t]['tensor_name'])\n",
    "        nn=len(list(layer_stats['tensor_name']))\n",
    "        print(f'Number of layers:{nn}, suspected:{len(suspected_layers)}, unquantized first {int(p*nn)} layers')\n",
    "        suspected_layers.extend(list(layer_stats[:int(p*nn)]['tensor_name']))\n",
    "        print(len(suspected_layers))\n",
    "        print(len(list(set(suspected_layers))))\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = rep(_dataset,N)\n",
    "        debug_options = tf.lite.experimental.QuantizationDebugOptions(denylisted_nodes=suspected_layers)\n",
    "        debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "            converter=converter,debug_dataset=rep(_dataset,N),debug_options=debug_options)\n",
    "        selective_quantized_model = debugger.get_nondebug_quantized_model()\n",
    "        open(QSelectiveName, \"wb\").write(selective_quantized_model)\n",
    "    return selective_quantized_model\n",
    "\n",
    "def calibrate(model,_dataset,name=CalibratedName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"calibrate...\\n\")\n",
    "    if (os.path.isfile(CalibratedName)):\n",
    "        print(f'calibrate: loading existing file {CalibratedName}')\n",
    "        with open(name, 'rb') as f:\n",
    "            calibrated_model = f.read()\n",
    "    else:\n",
    "        print(f\"calibrate producing file {CalibratedName}\")\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.representative_dataset = rep2(_dataset)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter._experimental_calibrate_only = True\n",
    "        converter.inference_input_type = input_dtype\n",
    "        converter.inference_output_type = output_dtype\n",
    "        converter.inference_input_shape = input_shape\n",
    "        converter.inference_output_shape = output_shape\n",
    "        calibrated_model = converter.convert()\n",
    "        open(name, \"wb\").write(calibrated_model)\n",
    "    return calibrated_model\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def explore_propogation(calibrated_model,_dataset,debugger_name=DebuggerPropogateName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"explore propogation...\\n\")\n",
    "    if (os.path.isfile(DebuggerPropogateName)):\n",
    "        print(f'explore propogation: loading existed file {DebuggerPropogateName}')\n",
    "        with open(debugger_name, 'rb') as f:\n",
    "            debugger=pickle.load(f)\n",
    "    elif (os.path.isfile(RESULTS_FILE_Propogate)):\n",
    "        print(f'explore propogate not required, existed file {RESULTS_FILE_Propogate}')\n",
    "        return\n",
    "    else:\n",
    "        print(f\"explore_propogation: Producing file {DebuggerPropogateName}\")\n",
    "        # Note that enable_numeric_verify and enable_whole_model_verify are set.\n",
    "        quantized_model = convert.mlir_quantize(\n",
    "            calibrated_model,\n",
    "            enable_numeric_verify=True,\n",
    "            enable_whole_model_verify=True)\n",
    "        debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "            quant_debug_model_content=quantized_model,\n",
    "            debug_dataset=rep2(_dataset))\n",
    "        #with open(debugger_name, 'wb') as f:\n",
    "        #    pickle.dump(debugger, f)\n",
    "    return debugger\n",
    "\n",
    "def explore_combinations(calibrated_model,suspected_layers=[],t=0.35,name=UQSelectiveName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"explore combination...\\n\")\n",
    "    if (os.path.isfile(name)):\n",
    "        print(f'explore combinations: loading existed file {name}')\n",
    "        with open(name, 'rb') as f:\n",
    "            selective_quantized_model = f.read()\n",
    "    else:\n",
    "        print(f\"explore_combinations: producing file {name}\")\n",
    "        layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "        suspected_layers.extend(list(layer_stats[layer_stats['rmse/scale'] > t]['tensor_name']))\n",
    "        suspected_layers.extend(list(layer_stats[:10]['tensor_name']))\n",
    "        selective_quantized_model = convert.mlir_quantize(calibrated_model, denylisted_nodes=suspected_layers)\n",
    "        open(name, \"wb\").write(selective_quantized_model)\n",
    "    return selective_quantized_model\n",
    "\n",
    "def explore_combinations2(calibrated_model,suspected_layers=[],name=UQSelectiveName):\n",
    "    print(\"\\n\\n\\n\\n***************************************************\")\n",
    "    print(\"explore combination...\\n\")\n",
    "    caching=False\n",
    "    if (os.path.isfile(name)) and caching:\n",
    "        print(f'explore combinations: loading existed file {name}')\n",
    "        with open(name, 'rb') as f:\n",
    "            selective_quantized_model = f.read()\n",
    "    else:\n",
    "        print(f\"explore_combinations: producing file {name}\")\n",
    "        selective_quantized_model = convert.mlir_quantize(calibrated_model, denylisted_nodes=suspected_layers)\n",
    "        with open(name, \"wb\") as f:\n",
    "            f.write(selective_quantized_model)\n",
    "    return \n",
    "\n",
    "'''\n",
    "def amend_input(m=CalibratedName):\n",
    "    interpreter = tf.lite.Interpreter(model_path=m)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    input_shape = input_details[0]['shape']\n",
    "    input_shape[1] = 608\n",
    "    input_shape[2] = 608\n",
    "    interpreter.resize_tensor_input(0, input_shape)\n",
    "    interpreter.allocate_tensors()\n",
    "    print(interpreter.get_input_details())\n",
    "    converter = tf.lite.TFLiteConverter.from_interpreter(interpreter)\n",
    "    #converter.allow_custom_ops = True  # If you have any custom ops in your model\n",
    "    tflite_model = converter.convert()\n",
    "    with open('modified_model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    global model,dataset,calibrated_model\n",
    "    model=load_model(m=ModelName)\n",
    "    model.summary()\n",
    "    dataset=load_dataset()\n",
    "    # Print the first 5 images in the dataset\n",
    "    for image in dataset.take(5):\n",
    "        print(image.shape)\n",
    "    #global calibrated_model\n",
    "    calibrated_model=calibrate(model,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f050129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import imp\n",
    "#imp.reload(tt)\n",
    "def evaluate(model_name, pkl_name):\n",
    "    #cmd='cd ../Evaluation; python ../Evaluation/eval_multiThread2.py '+args\n",
    "    #os.system(cmd)\n",
    "    mAP,APs=tt.main([\"--num_threads\",'64',\"--model_path\",model_name,\"--pkl_name\",pkl_name])\n",
    "    return mAP,APs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indexes(start_conv=-1,end_conv=-1):\n",
    "    ####\n",
    "    layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "    all_layers=list(layer_stats[:]['tensor_name'])\n",
    "    conv_layers=[]\n",
    "    for i,layer in enumerate(all_layers):\n",
    "        if 'conv' in layer or 'StatefulPartitionedCall' in layer:\n",
    "            conv_layers.append(layer)\n",
    "            \n",
    "    _n=len(conv_layers)\n",
    "    #cases=[ [ conv_layers[start:end+1] for end in range(start,_n) ] for start in range(0,_n) ]\n",
    "    #n_cases = [len(case) for case in cases ]\n",
    "    #N_cases = sum(n_cases)\n",
    "    cases=[  list(range(start,end+1))  for start in range(0,_n) for end in range(start,_n)]\n",
    "    N_cases = len(cases)\n",
    "    print(f'Total layers:{len(all_layers)}  Convs:{len(conv_layers)}  number of cases:{N_cases}')\n",
    "    #flatted_cases=[c for case in cases for c in case]\n",
    "    last_conv_indx=len(conv_layers)-1\n",
    "    for i,case in enumerate(cases):\n",
    "        start_conv=case[0]\n",
    "        end_conv=case[-1]\n",
    "        start_index=all_layers.index(conv_layers[start_conv])\n",
    "        if end_conv==last_conv_indx:\n",
    "            end_index=len(all_layers)-1\n",
    "        else:\n",
    "            end_index=all_layers.index(conv_layers[end_conv+1])\n",
    "        suspend=all_layers[0:start_index]+all_layers[end_index:]\n",
    "        #kk=list(set(all_layers)-set(suspend))\n",
    "        #print(f'quantizing conv layers from {start_conv} to {end_conv}')\n",
    "        #print(f'index {start_index} to {end_index}')\n",
    "        #print(all_layers[start_index:end_index])\n",
    "        #ttt=explore_combinations2(calibrated_model,suspected_layers=ss,name='2-3.tflite')'''\n",
    "        next_start_conv=cases[i+1]\n",
    "        next_end_conv=cases\n",
    "        yield i,N_cases,start_conv,end_conv,start_index,end_index,suspend\n",
    "        \n",
    "\n",
    "\n",
    "# +\n",
    "        \n",
    "def run():\n",
    "    output=os.getcwd()+\"/cases/\"\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "    i=0\n",
    "    pklDatafile=\"DataResults.pkl\"\n",
    "    dffile=\"df.csv\"\n",
    "    if os.path.isfile(dffile):\n",
    "        df=pd.read_csv(dffile,index_col=0)\n",
    "        #i=df.iloc[-1][0]+1\n",
    "        i=len(df)\n",
    "        print(f'Continue {dffile} from index {i}')\n",
    "    else:\n",
    "        response=input(\"Do you want to reset df.csv? yes/*   \")\n",
    "        if response==\"yes\" or response==\"Yes\":\n",
    "            df = pd.DataFrame(columns=[\"name\",\"mAP\"])\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    if os.path.isfile(pklDatafile):\n",
    "        with open(pklDatafile,'rb') as f:\n",
    "            Data=pickle.load(f)\n",
    "        print(f'{pklDatafile} is loaded')\n",
    "    else:\n",
    "        response=input(\"Do you want to reset DataResults.pkl? yes/*   \")\n",
    "        if response==\"yes\" or response==\"Yes\":\n",
    "            Data=[]\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    for c in generate_indexes():\n",
    "        if c[0]<i:\n",
    "            continue\n",
    "        input(f'i is {i}')\n",
    "        print(\"\\n\\n\\n*****************\\n\\n\\n\")\n",
    "        print(f'Case:{c[0]}/{c[1]}')\n",
    "        print(f'quantizing conv layers from {c[2]} to {c[3]}')\n",
    "        print(f'index {c[4]} to {c[5]}')        \n",
    "        _name=f'{c[2]}-{c[3]}'\n",
    "        m_name=output+_name+'.tflite'\n",
    "        p_name=_name+'.pkl'\n",
    "        \n",
    "        start_time=time.time()\n",
    "        explore_combinations2(calibrated_model,suspected_layers=c[-1],name=m_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Quantization finished time: {end_time-start_time}\")\n",
    "        \n",
    "        mAP,APs=evaluate(model_name=m_name,pkl_name=p_name)\n",
    "        end_time=time.time()\n",
    "        print(f\"{m_name} Evaluation finished time: {end_time-start_time}\")\n",
    "        \n",
    "        os.remove(m_name)\n",
    "        df.loc[c[0]]=[_name,mAP]\n",
    "        dct={\"i\":c[0],\"start_conv\":c[2], \"end_conv\":c[3], \"start_index\":c[4], \"end_index\":c[5],\"mAP\":mAP, \"APs\":APs}\n",
    "        Data.append(dct)\n",
    "        if c[0]%5==0:\n",
    "            df.to_csv(dffile)\n",
    "            with open(pklDatafile,'wb') as f:\n",
    "                pickle.dump(Data,f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# +\n",
    "#evaluate([])\n",
    "if __name__ == \"__main__\":\n",
    "    initialize()\n",
    "    if os.path.isfile(RESULTS_FILE):\n",
    "        run()\n",
    "    else:\n",
    "        quantized_model=quantize(model,dataset)\n",
    "        debugger=explore(model,dataset)\n",
    "        run_debugger(debugger,RESULTS_FILE)\n",
    "        run()\n",
    "\n",
    "\n",
    "# # +\n",
    "\n",
    "# + endofcell=\"----\"\n",
    "# # # +\n",
    "def run2():\n",
    "    ouput=os.getcwd()+\"/cases/\"\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    layer_stats = pd.read_csv(RESULTS_FILE)\n",
    "    all_layers=list(layer_stats[:]['tensor_name'])\n",
    "    conv_layers=[]\n",
    "    for i,layer in enumerate(all_layers):\n",
    "        if 'conv' in layer or 'StatefulPartitionedCall' in layer:\n",
    "            conv_layers.append(layer)\n",
    "            \n",
    "    _n=len(conv_layers)\n",
    "    #cases=[ [ conv_layers[start:end+1] for end in range(start,_n) ] for start in range(0,_n) ]\n",
    "    cases=[  list(range(start,end+1))  for start in range(0,_n) for end in range(start,_n)]\n",
    "    n_cases = [len(case) for case in cases ]\n",
    "    N_cases = sum(n_cases)\n",
    "    print(f'Total layers:{len(all_layers)}  Convs:{len(conv_layers)}  number of cases:{N_cases}')\n",
    "    \n",
    "    def data_case(i):\n",
    "        Data={}\n",
    "        start_conv=cases[i][0]\n",
    "        end_conv=cases[i][-1]\n",
    "        start_index=all_layers.index(conv_layers[start_conv])\n",
    "        if end_conv==len(conv_layers)-1:\n",
    "            end_index=len(all_layers)-1\n",
    "        else:\n",
    "            end_index=all_layers.index(conv_layers[end_conv+1])\n",
    "        suspend=all_layers[0:start_index]+all_layers[end_index:]\n",
    "        _name=f'{start_conv}-{end_conv}'\n",
    "        \n",
    "        Data['start_conv']=start_conv\n",
    "        Data['end_conv']=end_conv\n",
    "        Data['suspend']=suspend\n",
    "        Data['_name']=_name\n",
    "        return Data\n",
    "        \n",
    "    Data1=data_case(0)\n",
    "    thread = threading.Thread(target=explore_combinations2,args=(calibrated_model,suspected_layers:=c[-1],name:=m_name))\n",
    "    thread.start()\n",
    "    for j in range(1,len(cases)):\n",
    "        \n",
    "        #kk=list(set(all_layers)-set(suspend))\n",
    "        print(\"\\n\\n\\n*****************\")\n",
    "        print(f'quantizing conv layers from {start_conv} to {end_conv}')\n",
    "        print(f'index {start_index} to {end_index}')\n",
    "        print(all_layers[start_index:end_index])\n",
    "        print(f'Case:{i}/{N_cases}')\n",
    "        _name=f'{start_conv}-{end_conv}'\n",
    "        m_name=output+_name+'.tflite'\n",
    "        p_name=_name+'.pkl'\n",
    "        if i==0:\n",
    "            thread = threading.Thread(target=explore_combinations2,args=(calibrated_model,suspected_layers:=c[-1],name:=m_name))\n",
    "            thread.start()\n",
    "            thread.join()\n",
    "            \n",
    "        next_start_conv=cases[i+1][0]\n",
    "        next_end_conv=cases[i+1][-1]\n",
    "        next_start_index=all_layers.index(conv_layers[next_start_conv])\n",
    "        next_end_index=all_layers.index(conv_layers[next_end_conv+1])\n",
    "        next_suspend=all_layers[0:start_index]+all_layers[end_index:]\n",
    "        \n",
    "    for c in generate_indexes():\n",
    "        threads=[]\n",
    "        start_time=time.time()\n",
    "        print(\"\\n\\n\\n*****************\\n\\n\\n\")\n",
    "        print(f'Case:{c[0]}/{c[1]}')\n",
    "        _name=f'{c[2]}-{c[3]}'\n",
    "        m_name=output+_name+'.tflite'\n",
    "        p_name=_name+'.pkl'\n",
    "        thread = threading.Thread(target=explore_combinations2,args=(calibrated_model,suspected_layers:=c[-1],name:=m_name))\n",
    "        end_time=time.time()\n",
    "        print(f\"{mname} Quantization finished time: {end_time-start_time}\")\n",
    "        ## Trigger Evaluation\n",
    "        thread = threading.Thread(target=evaluate, args=[model_name:=m_name,pkl_name:=p_name])\n",
    "        threads.append(thread)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "\n",
    "\n",
    "def generate_cases_keras():\n",
    "    all_layers=[l.name for l in model.layers]\n",
    "    conv_layers=[name for (indx,name) in enumerate(all_layers) if 'conv' in name]\n",
    "    _n=len(conv_layers)\n",
    "    cases=[ [ conv_layers[start:end+1] for end in range(start,_n) ] for start in range(0,_n) ]\n",
    "    n_cases = [len(case) for case in cases ]\n",
    "    N_cases = sum(n_cases)\n",
    "    flatted_cases=[c for case in cases for c in case]\n",
    "    #test=flatted_cases[4]\n",
    "    #t=explore_combinations2(calibrated_model,suspected_layers=test,name='ttt.tflite')\n",
    "    return flatted_cases\n",
    "\n",
    "def run_keras():\n",
    "    global calibrated_model\n",
    "    threads=[]\n",
    "    for case in flatted_cases:\n",
    "        start_time=time.time()\n",
    "        c=f'{case[0]}-{case[-1]}'\n",
    "        mname=resdir+c+'.tflite'\n",
    "        print(f\"Quantizaing layers {c} --> {mname}\")\n",
    "        explore_combinations2(calibrated_model,suspected_layers=case,name=mname)\n",
    "        end_time=time.time()\n",
    "        print(f\"{mname} Quantization finished time: {end_time-start_time}\")\n",
    "        thread = threading.Thread(target=evaluate, args=[model_name:=mname,pkl_name:=f'{c}.pkl'])\n",
    "        threads.append(thread)\n",
    "        input(\"one_run...\")\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "\n",
    "# # + endofcell=\"--\"\n",
    "# -\n",
    "\n",
    "'''\n",
    "sq=selective_quantize(model,dataset,t=0.31,p=0.3)\n",
    "calibrated_model=calibrate(model,dataset)\n",
    "quantized_model=quantize(model,dataset)\n",
    "debugger=explore(model,dataset)\n",
    "run_debugger(debugger,RESULTS_FILE)\n",
    "Analyze(RESULTS_FILE_ANALYZED)\n",
    "selective_quantized=selective_quantize(model,dataset)\n",
    "calibrated_model=calibrate(model,dataset)\n",
    "debugger=explore_propogation(calibrated_model,dataset)\n",
    "run_debugger(debugger,RESULTS_FILE_Propogate)\n",
    "Analyze(RESULTS_FILE_Propogate_ANALYZED)\n",
    "calibrated_model=calibrate(model,dataset)\n",
    "selective_unquantized=explore_combinations(calibrated_model)'''\n",
    "\n",
    "\n",
    "# # # # # # %%timeit -n 1 -r 1\n",
    "def ttt():\n",
    "    QuantizedName='Yolo_files/1/YoloV3_quztized.tflite'\n",
    "    model = interpreter_wrapper.Interpreter(model_path=QuantizedName)\n",
    "    model.allocate_tensors()\n",
    "    model_format = 'TFLITE'\n",
    "    model_input_shape=(608,608)\n",
    "    #Ehsan input shape correctness\n",
    "    input_details = model.get_input_details()\n",
    "    output_details = model.get_output_details()\n",
    "    input_shape = input_details[0]['shape']\n",
    "\n",
    "    n=100\n",
    "    input_shape[0]=n\n",
    "    input_shape[1] = model_input_shape[0]\n",
    "    input_shape[2] = model_input_shape[1]\n",
    "    model.resize_tensor_input(0, input_shape)\n",
    "    model.allocate_tensors()\n",
    "    print(input_shape)\n",
    "    input_shape=[n,608,608,3]\n",
    "    input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "    # Set the input tensor to the interpreter\n",
    "    model.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    # Run the model on the GPU\n",
    "    with tf.device('/gpu:1'):\n",
    "        model.invoke()\n",
    "\n",
    "    # Get the output tensor from the interpreter\n",
    "    output_data = model.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    output_data\n",
    "# ---\n",
    "# --\n",
    "# ----"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py:light,ipynb"
  },
  "kernelspec": {
   "display_name": "qe",
   "language": "python",
   "name": "qe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
