{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow \n",
    "import time\n",
    "#pip install -U scikit-learn scipy matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    #Load dataset as train and test sets\n",
    "    global x_test,x_train,y_test,y_train,mnist_ds\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape(60000, 784)\n",
    "    x_test = x_test.reshape(10000, 784)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    num_classes = 10\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    mnist_train, _ = tf.keras.datasets.mnist.load_data()\n",
    "    images = tf.cast(mnist_train[0], tf.float32) / 255.0\n",
    "    mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    from keras.models import Sequential\n",
    "    from keras import models, layers\n",
    "    from keras import regularizers\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dropout(0.2,input_shape=(784,)))\n",
    "    model.add(keras.layers.Dense(1000,\n",
    "                            kernel_regularizer = regularizers.l2(0.01),\n",
    "                            activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(1000,\n",
    "                            kernel_regularizer = regularizers.l2(0.01),\n",
    "                            activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(10,  activation='softmax'))\n",
    "    #display the model summary\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mode(model):\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    hist = model.fit(x_train, y_train,\n",
    "                        batch_size=128,\n",
    "                        epochs=10,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test,y_test))\n",
    "    #Save the entire model in model.h5 file\n",
    "    model.save(\"trained_model.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(m):\n",
    "    model = tf.keras.models.load_model(m)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in mnist_ds.take(100):\n",
    "    yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_layer_names1 = ['dense_1']\n",
    "def convert_model_1(model,name='converted_quant_int_model1.tflite',quantize_annotations = quantize_layer_names1,partial=True):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    if partial:\n",
    "        converter.quantize_annotations = quantize_annotations\n",
    "    tflite_quant_int_model = converter.convert()\n",
    "    #saving converted model in \"converted_quant_model.tflite\" file\n",
    "    open(name, \"wb\").write(tflite_quant_int_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def just_convert_model_1(model,name='just_converted_quant_int_model1.tflite'):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_quant_int_model = converter.convert()\n",
    "    #saving converted model in \"converted_quant_model.tflite\" file\n",
    "    open(name, \"wb\").write(tflite_quant_int_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def prepare_dataset():\n",
    "    # Load the training data into a tf.data.Dataset\n",
    "    train_images_dir = \"train2017\"\n",
    "\n",
    "    def load_images(images_dir=train_images_dir):\n",
    "        images = []\n",
    "        labels = []\n",
    "        for image_filename in os.listdir(images_dir):\n",
    "            # Load the image\n",
    "            image = tf.io.read_file(os.path.join(images_dir, image_filename))\n",
    "            image = tf.image.decode_jpeg(image, channels=3)\n",
    "\n",
    "            # Load the label\n",
    "            #label = # code to load label from file\n",
    "\n",
    "            images.append(image)\n",
    "            #labels.append(label)\n",
    "        return images\n",
    "        #, labels\n",
    "\n",
    "    images = load_images(train_images_dir)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((images))\n",
    "    # Generate a representative dataset\n",
    "    return train_dataset\n",
    "\n",
    "def gen_rep():\n",
    "    train_dataset=prepare_dataset()    \n",
    "    representative_dataset = train_dataset.take(100).batch(1)\n",
    "    return representative_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for layer_name in quantize_layer_names:\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "    input_arrays = converter.get_input_arrays()\n",
    "    for input_array in input_arrays:\n",
    "        converter.quantizers[input_array].supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.quantizers[layer_name].supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "'''\n",
    "quantize_layer_names2 = ['dense_1']\n",
    "def convert_model_2(model,name='converted_quant_int_model2.tflite',quantize_annotations = quantize_layer_names2,partial=True):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    #converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = gen_rep()\n",
    "    if partial:\n",
    "        converter.quantize_annotations = quantize_annotations\n",
    "    tflite_quant_int_model = converter.convert()\n",
    "    #saving converted model in \"converted_quant_model.tflite\" file\n",
    "    open(name, \"wb\").write(tflite_quant_int_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate1(name='converted_quant_int_model1.tflite'):\n",
    "    # Load TFLite model and allocate tensors.\n",
    "    interpreter = \\\n",
    "        tf.lite.Interpreter(model_path=name)\n",
    "    interpreter.allocate_tensors()\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    # Test model on some input data.\n",
    "    input_shape = input_details[0]['shape']\n",
    "    acc=0\n",
    "    for i in range(len(x_test)):\n",
    "        input_data = x_test[i].reshape(input_shape)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        if(np.argmax(output_data) == np.argmax(y_test[i])):\n",
    "            acc+=1\n",
    "    acc = acc/len(x_test)\n",
    "    print(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(m='Yolov3.h5')\n",
    "model.summary()\n",
    "just_convert_model_1(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "30a4a38824aecb2ea03aa4df66d2cdcd9b269d7a636d811330742db328a4a2bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
